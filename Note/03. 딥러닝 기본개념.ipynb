{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5235e4",
   "metadata": {},
   "source": [
    "### 딥러닝 학습\n",
    "- 모델에 입력값을 넣었을때 출력값이 최대한 정답과 일치하게 하는것.\n",
    "- 최초 딥러닝 모델의 매개변수(w,b)를 무작위로 부여한후 반복학습을 통해 모델의 출력값이 최대한 정답과 일치되도록 매개변수를 조정하는 과정 \n",
    "\n",
    "##### 순전파(forward propagation)\n",
    ": 예측값을 계산하는 과정      \n",
    "\n",
    "##### 손실함수(Loss Function) / 비용함수(cost Function)\n",
    "- 출력값과 정답의 차이\n",
    "- 출력값이 정답에 일치할수록 손실함수의 값은 작아진다. \n",
    "- 보통 회귀에서는 평균제곱오차(Mean Squared Error: MSE)   \n",
    "- 분류에서는 크로스 엔트로피(Cross Entropy)를 사용   \n",
    "- 매개변수를 조절해서 손실함수의 값을 최저로 만드는 과정을 최적화(Optimization)이라 한다.   \n",
    "- 최적화 과정은 Optimizer를 통해 이뤄지며 이 Optimizer는 역전파 과정을 수행해서 딥러닝 모델의 매개변수를 최적화 한다.\n",
    "\n",
    "##### 최적화(Optimization)\n",
    "- 대표적인 방법은 경사 하강법(gradient descent)\n",
    "- 반복적으로 손실함수에 대한 모델 매개변수의 미분값(기울기)을 구한후 그 미분값에 반대방향으로 매개변수를 조절하면 결국 최저 손실함수값에 도달 한다.   \n",
    "- Batch 경사 하강법 : 전체 sample을 한번에 \n",
    "- SGD(Stochastic Gradient Descent:경사하강법): data를 sample별로 1개씩    \n",
    "- mini Batch 경사하강법 : sample갯수를 정해서 사용    \n",
    "\n",
    "##### 역전파(back propagation)\n",
    "- Optimizer는 손실함수의 값을 최소화 하기 위해 역전파를 사용해 딥러닝 모델의 모든 매개변수를 변경한다.  \n",
    "- 손실함수의 값을 최적화 한다는 것은 정답과 예측값의 차이를 최소화 한다는 것이며 에러율을 최저로 줄인다는 의미  \n",
    "\n",
    "##### 드롭아웃(Drop Out)\n",
    "- 드롭아웃은 해당 Node의 갯수를 줄이는 방법으로 과대적합을 피한다.\n",
    "- 드롭아웃을 사용하면 모델에 앙상블 효과를 준다.   \n",
    "\n",
    "##### 조기종료(Early Stopping)\n",
    "- 학습 횟수에 따라 검증 정확도가 꾸준히 떨이지는 시점이 발견되면 학습을 중단.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
